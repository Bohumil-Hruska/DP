import React, { useState, useEffect, useRef } from "react";
import { Link } from "react-router-dom";
import axios from "axios";

const VoiceControl = ({ showMessage }) => {
    const [listening, setListening] = useState(false);
    const [recognized, setRecognized] = useState("");

    const wsRef = useRef(null);
    const audioContextRef = useRef(null);
    const processorRef = useRef(null);
    const streamRef = useRef(null);
    const lastCommandRef = useRef({ text: "", ts: 0 });

    // ‚úÖ TTS audio player
    const ttsAudioRef = useRef(null);
    const unlockedRef = useRef(false);

    const unlockAudio = async () => {
        if (unlockedRef.current) return;
        try {
            const a = new Audio();
            a.muted = true;
            await a.play();
            a.pause();
            unlockedRef.current = true;
        } catch {
            // nevad√≠, nƒõkter√© prohl√≠≈æeƒçe to ignoruj√≠
        }
    };

    const speakHuman = async (text) => {
        const msg = (text || "").toString().trim();
        if (!msg) return;

        // stop p≈ôedchoz√≠ audio, aby se nep≈ôekr√Ωvalo
        if (ttsAudioRef.current) {
            try { ttsAudioRef.current.pause(); } catch {}
            ttsAudioRef.current = null;
        }

        const r = await fetch("/api/tts", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text: msg }),
        });

        if (!r.ok) {
            throw new Error(`TTS failed: ${r.status}`);
        }

        const blob = await r.blob();
        const url = URL.createObjectURL(blob);

        const a = new Audio(url);
        a.volume = 1.0;
        ttsAudioRef.current = a;

        a.onended = () => {
            URL.revokeObjectURL(url);
            if (ttsAudioRef.current === a) ttsAudioRef.current = null;
        };
        a.onerror = () => {
            URL.revokeObjectURL(url);
            if (ttsAudioRef.current === a) ttsAudioRef.current = null;
        };

        await a.play();
    };

    const startRecording = async () => {
        if (listening) return;
        setListening(true);

        // ‚úÖ d≈Øle≈æit√©: autoplay unlock p≈ôi user gesture
        await unlockAudio();

        try {
            wsRef.current = new WebSocket("wss://app.rb4home.eu/ws/");
            wsRef.current.binaryType = "arraybuffer";

            wsRef.current.onmessage = (msg) => {
                const text = msg.data;
                if (!text) return;

                const now = Date.now();
                const last = lastCommandRef.current;

                // pokud stejn√© jako minule a do 1200 ms, ignoruj
                if (text === last.text && (now - last.ts) < 1200) return;

                lastCommandRef.current = { text, ts: now };

                setRecognized(text);
                showMessage("Rozpozn√°n p≈ô√≠kaz: " + text, false);
                sendCommandToNode(text);
            };

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            streamRef.current = stream;

            audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000,
            });

            const source = audioContextRef.current.createMediaStreamSource(stream);
            const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);

            processor.onaudioprocess = (e) => {
                if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
                    const input = e.inputBuffer.getChannelData(0);
                    const int16 = floatTo16BitPCM(input);
                    wsRef.current.send(int16);
                }
            };

            source.connect(processor);

            // ‚ö†Ô∏è pokud ti to dƒõl√° echo, tohle odpoj:
            processor.connect(audioContextRef.current.destination);

            processorRef.current = processor;

            showMessage("üé§ Nep≈ôetr≈æit√Ω poslech spu≈°tƒõn", false);
        } catch (err) {
            showMessage("Chyba: " + err.message, true);
            setListening(false);
        }
    };

    const stopRecording = () => {
        setListening(false);

        if (processorRef.current) processorRef.current.disconnect();
        if (audioContextRef.current) audioContextRef.current.close();

        if (streamRef.current) {
            streamRef.current.getTracks().forEach((t) => t.stop());
        }
        if (wsRef.current) wsRef.current.close();

        // stopni TTS, pokud hraje
        if (ttsAudioRef.current) {
            try { ttsAudioRef.current.pause(); } catch {}
            ttsAudioRef.current = null;
        }

        showMessage("‚èπÔ∏è Poslech zastaven", false);
    };

    const sendCommandToNode = async (text) => {
        try {
            console.log("[VOICE] sending command:", text);

            const res = await axios.post(
                "/api/voice/execute",
                { command: text },
                { withCredentials: true }
            );

            console.log("[VOICE] backend response:", res.data);

            const message = res.data.message || "P≈ô√≠kaz zpracov√°n.";
            showMessage(message, false);

            console.log("[VOICE] speaking:", message);
            await unlockAudio();
            speakHuman(message).catch((e) => console.warn("[VOICE] TTS failed:", e));
        } catch (err) {
            console.error("[VOICE] execute error:", err);
            showMessage("Chyba p≈ôi vykon√°v√°n√≠ p≈ô√≠kazu.", true);

            await unlockAudio();
            speakHuman("Nastala chyba p≈ôi vykon√°v√°n√≠ p≈ô√≠kazu.").catch(() => {});
        }
    };

    const floatTo16BitPCM = (float32Array) => {
        const buffer = new ArrayBuffer(float32Array.length * 2);
        const view = new DataView(buffer);
        let offset = 0;
        for (let i = 0; i < float32Array.length; i++, offset += 2) {
            let s = Math.max(-1, Math.min(1, float32Array[i]));
            view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
        }
        return buffer;
    };

    useEffect(() => {
        return () => stopRecording();
        // eslint-disable-next-line react-hooks/exhaustive-deps
    }, []);

    return (
        <div className="container py-5">
            <div className="d-flex justify-content-between align-items-center mb-4">
                <h2 className="mb-0">Hlasov√© ovl√°d√°n√≠</h2>
                <Link to="/" className="btn btn-secondary">
                    Zpƒõt na Dashboard
                </Link>
            </div>

            <button
                className="btn btn-outline-secondary ms-2"
                onClick={async () => {
                    const msg = "Test hlasov√© odezvy funguje.";
                    showMessage(msg, false);
                    await unlockAudio();
                    speakHuman(msg).catch(console.warn);
                }}
            >
                üîà Test TTS
            </button>

            {!listening ? (
                <button className="btn btn-primary" onClick={startRecording}>
                    üéôÔ∏è Spustit nep≈ôetr≈æit√Ω poslech
                </button>
            ) : (
                <button className="btn btn-danger" onClick={stopRecording}>
                    ‚èπÔ∏è Zastavit poslech
                </button>
            )}

            {recognized && (
                <div className="alert alert-info mt-3">
                    Rozpoznan√Ω p≈ô√≠kaz: <strong>{recognized}</strong>
                </div>
            )}
        </div>
    );
};

export default VoiceControl;
